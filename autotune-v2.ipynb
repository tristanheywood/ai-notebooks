{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show that Triton autotune is broken due to warmup issues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim\n",
    "\n",
    "Create an instance of Triton kernel + @autotune on a100 where the autotuner picks the wrong config, due to `do_bench` not doing enough warmup by default."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ops.flash_attention` isn't good because it's basically not tunable - it breaks for most meta param values.\n",
    "\n",
    "Try `ops.matmul`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton.ops.matmul import _kernel\n",
    "\n",
    "# Extract original (non-autotuned) kernel.\n",
    "matmul_kernel = _kernel.fn.fn\n",
    "\n",
    "\n",
    "# Based on `triton.ops.matmul._matmul._call`, but with exposed meta-params.\n",
    "def matmul_dispatch(a,\n",
    "                    b,\n",
    "                    BLOCK_M=64,\n",
    "                    BLOCK_N=64,\n",
    "                    BLOCK_K=64,\n",
    "                    GROUP_M=8,\n",
    "                    SPLIT_K=1,\n",
    "                    EVEN_K=True):\n",
    "    device = a.device\n",
    "    # handle non-contiguous inputs if necessary\n",
    "    if a.stride(0) > 1 and a.stride(1) > 1:\n",
    "        a = a.contiguous()\n",
    "    if b.stride(0) > 1 and b.stride(1) > 1:\n",
    "        b = b.contiguous()\n",
    "    # checks constraints\n",
    "    assert a.shape[1] == b.shape[0], \"incompatible dimensions\"\n",
    "    M, K = a.shape\n",
    "    _, N = b.shape\n",
    "    # allocates output\n",
    "    c = torch.empty((M, N), device=device, dtype=a.dtype)\n",
    "    # accumulator types\n",
    "    ACC_TYPE = tl.float32 if a.dtype in [\n",
    "        torch.float16, torch.bfloat16, torch.float32\n",
    "    ] else tl.int32\n",
    "    # launch kernel\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_M']) * triton.cdiv(\n",
    "        N, META['BLOCK_N']), META['SPLIT_K'])\n",
    "    _kernel[grid](a,\n",
    "                  b,\n",
    "                  c,\n",
    "                  M,\n",
    "                  N,\n",
    "                  K,\n",
    "                  a.stride(0),\n",
    "                  a.stride(1),\n",
    "                  b.stride(0),\n",
    "                  b.stride(1),\n",
    "                  c.stride(0),\n",
    "                  c.stride(1),\n",
    "                  GROUP_M=8,\n",
    "                  ACC_TYPE=ACC_TYPE)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((2048, 1024), device=\"cuda\")\n",
    "b = torch.rand((1024, 512), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1930, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a @ b - matmul_dispatch(a, b)).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.bench import MetaParamGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_grid = MetaParamGrid(min_val_prod=100_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

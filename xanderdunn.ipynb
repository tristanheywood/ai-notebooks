{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "# FIXME: This can produce a CUDA illegal access out of bounds error if d_model and batch_size aren't a power of 2\n",
    "def gelu_partial_layer_fused_forward(\n",
    "        # Pointers to matrices\n",
    "        x_ptr, W_ptr, A_ptr, z1_ptr, z2_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. stride_xm is how much to increase x_ptr\n",
    "        # by to get the element one row down (A has M rows)\n",
    "        stride_xm, stride_xk,\n",
    "        stride_Wk, stride_Wn,\n",
    "        stride_Am, stride_An,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    1) Compute Z = matmul(x, W) into two halves, Z1 and Z2\n",
    "    2) Compute element-wise multiply A = Z1 * gelu(Z2), this is the activation\n",
    "    3) Return A\n",
    "    x has shape (M, K), W has shape (K, N) and A has shape (M, N//2)\n",
    "    \"\"\"\n",
    "    # L2 Cache Optimizations\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # Create pointers for the first blocks of x and W.\n",
    "    offs_xm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_Wn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    x_ptrs = x_ptr + (offs_xm[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n",
    "    W_left_ptrs = W_ptr + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "    # offset the start by half of the number of columns\n",
    "    W_right_ptrs = W_ptr + (N // 2) + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "\n",
    "    z1 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    z2 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    # Matrix multiply A and B, accumulating the first half of columns into x1 and\n",
    "    # the second half of columns into x2\n",
    "    for _ in range(0, K, BLOCK_SIZE_K): # type: ignore\n",
    "        x = tl.load(x_ptrs)\n",
    "\n",
    "        W_left = tl.load(W_left_ptrs)\n",
    "        z1 += tl.dot(x, W_left)\n",
    "\n",
    "        W_right = tl.load(W_right_ptrs)\n",
    "        z2 += tl.dot(x, W_right)\n",
    "\n",
    "        # Advance the ptrs to the next K block\n",
    "        x_ptrs += BLOCK_SIZE_K * stride_xk\n",
    "        W_left_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "        W_right_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "\n",
    "    # Store z1 in z1_ptr\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offsets = stride_Am * offs_cm[:, None] + stride_An * offs_cn[None, :]\n",
    "    outs_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N // 2)\n",
    "    tl.store(z1_ptr + offsets, z1, mask=outs_mask)\n",
    "    # Store z2 in z2_ptr\n",
    "    tl.store(z2_ptr + offsets, z2, mask=outs_mask)\n",
    "\n",
    "    # Element-wise multiply of z1 and gelu(z2)\n",
    "    z2 = gelu_fast(z2)\n",
    "    c = z1 * z2\n",
    "    c = c.to(tl.float16)\n",
    "\n",
    "    # Write back the block of the output matrix C\n",
    "    tl.store(A_ptr + offsets, c, mask=outs_mask)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def gelu_fast(x):\n",
    "    \"\"\"\n",
    "    From https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\n",
    "    0.5 * x * (1 + tanh(sqrt(2/pi)) * (x + 0.044715 * x**3))\n",
    "    0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * (x + 0.044715 * x * x * x)))\n",
    "    \"\"\"\n",
    "    return (\n",
    "            0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * x * (1.0 + 0.044715 * x * x)))\n",
    "           )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split inputs and compute one after other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "# FIXME: This can produce a CUDA illegal access out of bounds error if d_model and batch_size aren't a power of 2\n",
    "def gelu_partial_layer_fused_forward_splitW(\n",
    "        # Pointers to matrices\n",
    "        x_ptr, Wl_ptr, Wr_ptr, A_ptr, z1_ptr, z2_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. stride_xm is how much to increase x_ptr\n",
    "        # by to get the element one row down (A has M rows)\n",
    "        stride_xm, stride_xk,\n",
    "        stride_Wk, stride_Wn,\n",
    "        stride_Am, stride_An,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    1) Compute Z = matmul(x, W) into two halves, Z1 and Z2\n",
    "    2) Compute element-wise multiply A = Z1 * gelu(Z2), this is the activation\n",
    "    3) Return A\n",
    "    x has shape (M, K), W has shape (K, N) and A has shape (M, N//2)\n",
    "    \"\"\"\n",
    "    # L2 Cache Optimizations\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # Create pointers for the first blocks of x and W.\n",
    "    offs_xm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_Wn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    x_ptrs = x_ptr + (offs_xm[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n",
    "    W_left_ptrs = Wl_ptr + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "\n",
    "    z1 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for _ in range(0, K, BLOCK_SIZE_K): # type: ignore\n",
    "        x = tl.load(x_ptrs)\n",
    "\n",
    "        W_left = tl.load(W_left_ptrs)\n",
    "        z1 += tl.dot(x, W_left)\n",
    "\n",
    "        # Advance the ptrs to the next K block\n",
    "        x_ptrs += BLOCK_SIZE_K * stride_xk\n",
    "        W_left_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "\n",
    "    x_ptrs = x_ptr + (offs_xm[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n",
    "    W_right_ptrs = Wr_ptr + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "    \n",
    "    z2 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for _ in range(0, K, BLOCK_SIZE_K): # type: ignore\n",
    "        x = tl.load(x_ptrs)\n",
    "\n",
    "        W_right = tl.load(W_right_ptrs)\n",
    "        z2 += tl.dot(x, W_right)\n",
    "\n",
    "        # Advance the ptrs to the next K block\n",
    "        x_ptrs += BLOCK_SIZE_K * stride_xk\n",
    "        W_right_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "\n",
    "    # Store z1 in z1_ptr\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offsets = stride_Am * offs_cm[:, None] + stride_An * offs_cn[None, :]\n",
    "    outs_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N // 2)\n",
    "    tl.store(z1_ptr + offsets, z1, mask=outs_mask)\n",
    "    # Store z2 in z2_ptr\n",
    "    tl.store(z2_ptr + offsets, z2, mask=outs_mask)\n",
    "\n",
    "    # Element-wise multiply of z1 and gelu(z2)\n",
    "    z2 = gelu_fast(z2)\n",
    "    c = z1 * z2\n",
    "    c = c.to(tl.float16)\n",
    "\n",
    "    # Write back the block of the output matrix C\n",
    "    tl.store(A_ptr + offsets, c, mask=outs_mask)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def gelu_fast(x):\n",
    "    \"\"\"\n",
    "    From https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\n",
    "    0.5 * x * (1 + tanh(sqrt(2/pi)) * (x + 0.044715 * x**3))\n",
    "    0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * (x + 0.044715 * x * x * x)))\n",
    "    \"\"\"\n",
    "    return (\n",
    "            0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * x * (1.0 + 0.044715 * x * x)))\n",
    "           )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One accumulator, mask the gelu calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "# FIXME: This can produce a CUDA illegal access out of bounds error if d_model and batch_size aren't a power of 2\n",
    "def gelu_partial_layer_fused_forward_oneacc(\n",
    "        # Pointers to matrices\n",
    "        x_ptr, W_ptr, A_ptr, z1_ptr, z2_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. stride_xm is how much to increase x_ptr\n",
    "        # by to get the element one row down (A has M rows)\n",
    "        stride_xm, stride_xk,\n",
    "        stride_Wk, stride_Wn,\n",
    "        stride_Am, stride_An,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    1) Compute Z = matmul(x, W) into two halves, Z1 and Z2\n",
    "    2) Compute element-wise multiply A = Z1 * gelu(Z2), this is the activation\n",
    "    3) Return A\n",
    "    x has shape (M, K), W has shape (K, N) and A has shape (M, N//2)\n",
    "    \"\"\"\n",
    "    # L2 Cache Optimizations\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # Create pointers for the first blocks of x and W.\n",
    "    offs_xm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_Wn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K) * 2\n",
    "    x_ptrs = x_ptr + (offs_xm[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n",
    "    W_ptrs = W_ptr + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "    # offset the start by half of the number of columns\n",
    "    # W_right_ptrs = W_ptr + (N // 2) + (offs_k[:, None] * stride_Wk + offs_Wn[None, :] * stride_Wn)\n",
    "\n",
    "    z1 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    # z2 = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    # Matrix multiply A and B, accumulating the first half of columns into x1 and\n",
    "    # the second half of columns into x2\n",
    "    for _ in range(0, K, BLOCK_SIZE_K): # type: ignore\n",
    "        x = tl.load(x_ptrs)\n",
    "\n",
    "        W_left = tl.load(W_left_ptrs)\n",
    "        z1 += tl.dot(x, W_left)\n",
    "\n",
    "        W_right = tl.load(W_right_ptrs)\n",
    "        z2 += tl.dot(x, W_right)\n",
    "\n",
    "        # Advance the ptrs to the next K block\n",
    "        x_ptrs += BLOCK_SIZE_K * stride_xk\n",
    "        W_left_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "        W_right_ptrs += BLOCK_SIZE_K * stride_Wk\n",
    "\n",
    "    # Store z1 in z1_ptr\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offsets = stride_Am * offs_cm[:, None] + stride_An * offs_cn[None, :]\n",
    "    outs_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N // 2)\n",
    "    tl.store(z1_ptr + offsets, z1, mask=outs_mask)\n",
    "    # Store z2 in z2_ptr\n",
    "    tl.store(z2_ptr + offsets, z2, mask=outs_mask)\n",
    "\n",
    "    # Element-wise multiply of z1 and gelu(z2)\n",
    "    z2 = gelu_fast(z2)\n",
    "    c = z1 * z2\n",
    "    c = c.to(tl.float16)\n",
    "\n",
    "    # Write back the block of the output matrix C\n",
    "    tl.store(A_ptr + offsets, c, mask=outs_mask)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def gelu_fast(x):\n",
    "    \"\"\"\n",
    "    From https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\n",
    "    0.5 * x * (1 + tanh(sqrt(2/pi)) * (x + 0.044715 * x**3))\n",
    "    0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * (x + 0.044715 * x * x * x)))\n",
    "    \"\"\"\n",
    "    return (\n",
    "            0.5 * x * (1.0 + tl.libdevice.tanh(0.7978845608028654 * x * (1.0 + 0.044715 * x * x)))\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu_partial_layer(x, W):\n",
    "    # checks constraints\n",
    "    assert x.shape[1] == W.shape[0], \"incompatible dimensions\"\n",
    "    assert x.is_contiguous(), \"matrix A must be contiguous\"\n",
    "    assert W.is_contiguous(), \"matrix B must be contiguous\"\n",
    "    M, K = x.shape\n",
    "    K, N = W.shape\n",
    "    assert (\n",
    "            K % 16 == 0\n",
    "            ), \"We don't check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K\"\n",
    "    # allocates output\n",
    "    A = torch.empty((M, N // 2), device=x.device, dtype=x.dtype)\n",
    "    z1 = torch.empty((M, N // 2), device=x.device, dtype=x.dtype) # same dimensions as the weights\n",
    "    z2 = torch.empty((M, N // 2), device=x.device, dtype=x.dtype)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (\n",
    "            triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n",
    "            )\n",
    "    gelu_partial_layer_fused_forward[grid]( # type: ignore\n",
    "        x, W, A, z1, z2,\n",
    "        M, N, K,\n",
    "        x.stride(0), x.stride(1),\n",
    "        W.stride(0), W.stride(1),\n",
    "        A.stride(0), A.stride(1),\n",
    "        # In production we would not want to hardcode these, but likely want to\n",
    "        # find them via triton's autotuner.\n",
    "        # BLOCK_SIZE_M=32, # type: ignore\n",
    "        # BLOCK_SIZE_N=64, # type: ignore\n",
    "        # BLOCK_SIZE_K=16, # type: ignore\n",
    "        # GROUP_SIZE_M=8, # type: ignore\n",
    "    )\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu_partial_layer_splitW(x, Wl, Wr):\n",
    "    # checks constraints\n",
    "    assert x.shape[1] == Wl.shape[0], \"incompatible dimensions\"\n",
    "    assert x.is_contiguous(), \"matrix A must be contiguous\"\n",
    "    assert Wl.is_contiguous(), \"matrix B must be contiguous\"\n",
    "    M, K = x.shape\n",
    "    N = Wl.shape[1] * 2\n",
    "    assert (\n",
    "            K % 16 == 0\n",
    "            ), \"We don't check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K\"\n",
    "    # allocates output\n",
    "    A = torch.empty((M, N // 2), device=x.device, dtype=x.dtype)\n",
    "    z1 = torch.empty((M, N // 2), device=x.device, dtype=x.dtype) # same dimensions as the weights\n",
    "    z2 = torch.empty((M, N // 2), device=x.device, dtype=x.dtype)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (\n",
    "            triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n",
    "            )\n",
    "    gelu_partial_layer_fused_forward_splitW[grid]( # type: ignore\n",
    "        x, Wl, Wr, A, z1, z2,\n",
    "        M, N, K,\n",
    "        x.stride(0), x.stride(1),\n",
    "        Wl.stride(0), Wl.stride(1),\n",
    "        A.stride(0), A.stride(1),\n",
    "        # In production we would not want to hardcode these, but likely want to\n",
    "        # find them via triton's autotuner.\n",
    "        # BLOCK_SIZE_M=32, # type: ignore\n",
    "        # BLOCK_SIZE_N=64, # type: ignore\n",
    "        # BLOCK_SIZE_K=16, # type: ignore\n",
    "        # GROUP_SIZE_M=8, # type: ignore\n",
    "    )\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchNN():\n",
    "    def __init__(self, d_model: int):\n",
    "        # TODO: Add the bias back once the bias addition is added to the triton kernel\n",
    "        self.linear = torch.nn.Linear(d_model, 8 * d_model, device='cuda', dtype=torch.float16, bias=False)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.z1: torch.Tensor | None = None\n",
    "        self.z2: torch.Tensor | None = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        Z = self.linear(x)\n",
    "        z1, z2 = torch.chunk(Z, 2, dim=(Z.ndim - 1))\n",
    "        self.z1 = z1\n",
    "        self.z2 = z2\n",
    "        A = z1 * self.gelu(z2)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness():\n",
    "    print(\"Linear layer -> split in two by column -> GELU on the second half -> element-wise multiply of the first and second halves\")\n",
    "    print(\"In both pytorch and triton to compare correctness...\")\n",
    "    sizes = [2**i for i in range(6, 12)]\n",
    "    print(\"sizes = \", sizes)\n",
    "    for size in sizes:\n",
    "        batch_size = size # TODO: The backprop only works if this is square, where batch_size == d_model\n",
    "        d_model = size\n",
    "        torch.manual_seed(0)\n",
    "        # input to feed forward\n",
    "        x = torch.randn((batch_size, d_model), device='cuda', dtype=torch.float16)\n",
    "\n",
    "        # ptyroch\n",
    "        torch_nn = TorchNN(d_model)\n",
    "        torch_forward = torch_nn.forward(x)\n",
    "        assert torch_nn.z1 is not None\n",
    "        assert torch_nn.z2 is not None\n",
    "        assert not torch.isnan(torch_nn.z1).any()\n",
    "        assert not torch.isinf(torch_nn.z1).any()\n",
    "\n",
    "        linear_weights = torch_nn.linear.state_dict()[\"weight\"].T.contiguous()\n",
    "        triton_forward = gelu_partial_layer(x, linear_weights)\n",
    "\n",
    "        triton.testing.assert_almost_equal(triton_forward, torch_forward)\n",
    "        print(f\"Forward ({size}, {size}): ✅ Triton and Torch match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer -> split in two by column -> GELU on the second half -> element-wise multiply of the first and second halves\n",
      "In both pytorch and triton to compare correctness...\n",
      "sizes =  [64, 128, 256, 512, 1024, 2048]\n",
      "Forward (64, 64): ✅ Triton and Torch match\n",
      "Forward (128, 128): ✅ Triton and Torch match\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m check_correctness()\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mcheck_correctness\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39misinf(torch_nn\u001b[39m.\u001b[39mz1)\u001b[39m.\u001b[39many()\n\u001b[1;32m     21\u001b[0m linear_weights \u001b[39m=\u001b[39m torch_nn\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mstate_dict()[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m---> 22\u001b[0m triton_forward \u001b[39m=\u001b[39m gelu_partial_layer(x, linear_weights)\n\u001b[1;32m     24\u001b[0m triton\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_almost_equal(triton_forward, torch_forward)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mForward (\u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m): ✅ Triton and Torch match\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36mgelu_partial_layer\u001b[0;34m(x, W)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# 1D launch kernel where each block gets its own program.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m grid \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m META: (\n\u001b[1;32m     17\u001b[0m         triton\u001b[39m.\u001b[39mcdiv(M, META[\u001b[39m'\u001b[39m\u001b[39mBLOCK_SIZE_M\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m*\u001b[39m triton\u001b[39m.\u001b[39mcdiv(N, META[\u001b[39m'\u001b[39m\u001b[39mBLOCK_SIZE_N\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     18\u001b[0m         )\n\u001b[0;32m---> 19\u001b[0m gelu_partial_layer_fused_forward[grid]( \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m     x, W, A, z1, z2,\n\u001b[1;32m     21\u001b[0m     M, N, K,\n\u001b[1;32m     22\u001b[0m     x\u001b[39m.\u001b[39;49mstride(\u001b[39m0\u001b[39;49m), x\u001b[39m.\u001b[39;49mstride(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     23\u001b[0m     W\u001b[39m.\u001b[39;49mstride(\u001b[39m0\u001b[39;49m), W\u001b[39m.\u001b[39;49mstride(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     24\u001b[0m     A\u001b[39m.\u001b[39;49mstride(\u001b[39m0\u001b[39;49m), A\u001b[39m.\u001b[39;49mstride(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     25\u001b[0m     \u001b[39m# In production we would not want to hardcode these, but likely want to\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# find them via triton's autotuner.\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m# BLOCK_SIZE_M=32, # type: ignore\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m# BLOCK_SIZE_N=64, # type: ignore\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m# BLOCK_SIZE_K=16, # type: ignore\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# GROUP_SIZE_M=8, # type: ignore\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m A\n",
      "File \u001b[0;32m~/triton/python/triton/runtime/autotuner.py:77\u001b[0m, in \u001b[0;36mAutotuner.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m pruned_configs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprune_configs(kwargs)\n\u001b[1;32m     76\u001b[0m bench_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 77\u001b[0m timings \u001b[39m=\u001b[39m {config: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bench(\u001b[39m*\u001b[39margs, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m            \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m pruned_configs}\n\u001b[1;32m     79\u001b[0m bench_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbench_time \u001b[39m=\u001b[39m bench_end \u001b[39m-\u001b[39m bench_start\n",
      "File \u001b[0;32m~/triton/python/triton/runtime/autotuner.py:77\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m pruned_configs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprune_configs(kwargs)\n\u001b[1;32m     76\u001b[0m bench_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 77\u001b[0m timings \u001b[39m=\u001b[39m {config: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bench(\u001b[39m*\u001b[39;49margs, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m            \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m pruned_configs}\n\u001b[1;32m     79\u001b[0m bench_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbench_time \u001b[39m=\u001b[39m bench_end \u001b[39m-\u001b[39m bench_start\n",
      "File \u001b[0;32m~/triton/python/triton/runtime/autotuner.py:65\u001b[0m, in \u001b[0;36mAutotuner._bench\u001b[0;34m(self, config, *args, **meta)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn\u001b[39m.\u001b[39mrun(\u001b[39m*\u001b[39margs, num_warps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mnum_warps, num_stages\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mnum_stages, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcurrent)\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m do_bench(kernel_call, percentiles\u001b[39m=\u001b[39;49m(\u001b[39m0.5\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.8\u001b[39;49m))\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m OutOfResources:\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/triton/python/triton/testing.py:147\u001b[0m, in \u001b[0;36mdo_bench\u001b[0;34m(fn, warmup, rep, grad_to_none, percentiles, record_clocks, fast_flush)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m# Estimate the runtime of the function\u001b[39;00m\n\u001b[1;32m    146\u001b[0m fn()\n\u001b[0;32m--> 147\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49msynchronize()\n\u001b[1;32m    148\u001b[0m start_event \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mEvent(enable_timing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    149\u001b[0m end_event \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mEvent(enable_timing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:711\u001b[0m, in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    709\u001b[0m _lazy_init()\n\u001b[1;32m    710\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n\u001b[0;32m--> 711\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_synchronize()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "check_correctness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness_splitW():\n",
    "    print(\"Linear layer -> split in two by column -> GELU on the second half -> element-wise multiply of the first and second halves\")\n",
    "    print(\"In both pytorch and triton to compare correctness...\")\n",
    "    sizes = [2**i for i in range(6, 12)]\n",
    "    print(\"sizes = \", sizes)\n",
    "    for size in sizes:\n",
    "        batch_size = size # TODO: The backprop only works if this is square, where batch_size == d_model\n",
    "        d_model = size\n",
    "        torch.manual_seed(0)\n",
    "        # input to feed forward\n",
    "        x = torch.randn((batch_size, d_model), device='cuda', dtype=torch.float16)\n",
    "\n",
    "        # ptyroch\n",
    "        torch_nn = TorchNN(d_model)\n",
    "        torch_forward = torch_nn.forward(x)\n",
    "        assert torch_nn.z1 is not None\n",
    "        assert torch_nn.z2 is not None\n",
    "        assert not torch.isnan(torch_nn.z1).any()\n",
    "        assert not torch.isinf(torch_nn.z1).any()\n",
    "\n",
    "        linear_weights = torch_nn.linear.state_dict()[\"weight\"].T.contiguous()\n",
    "        Wl, Wr = torch.chunk(linear_weights, 2, dim=1)\n",
    "        Wl = Wl.contiguous()\n",
    "        Wr = Wr.contiguous()\n",
    "        triton_forward = gelu_partial_layer_splitW(x, Wl, Wr)\n",
    "\n",
    "        triton.testing.assert_almost_equal(triton_forward, torch_forward)\n",
    "        print(f\"Forward ({size}, {size}): ✅ Triton and Torch match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer -> split in two by column -> GELU on the second half -> element-wise multiply of the first and second halves\n",
      "In both pytorch and triton to compare correctness...\n",
      "sizes =  [64, 128, 256, 512, 1024, 2048]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m check_correctness_splitW()\n",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m, in \u001b[0;36mcheck_correctness_splitW\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[39m=\u001b[39m size \u001b[39m# TODO: The backprop only works if this is square, where batch_size == d_model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m d_model \u001b[39m=\u001b[39m size\n\u001b[0;32m----> 9\u001b[0m torch\u001b[39m.\u001b[39;49mmanual_seed(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# input to feed forward\u001b[39;00m\n\u001b[1;32m     11\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((batch_size, d_model), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmanual_seed_all(seed)\n\u001b[1;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m         default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    111\u001b[0m         default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 113\u001b[0m _lazy_call(cb, seed_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:192\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lazy_call\u001b[39m(callable, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 192\u001b[0m         callable()\n\u001b[1;32m    193\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m         \u001b[39m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         \u001b[39m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    196\u001b[0m         \u001b[39m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m         \u001b[39mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[1;32m    110\u001b[0m     default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 111\u001b[0m     default_generator\u001b[39m.\u001b[39;49mmanual_seed(seed)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "check_correctness_splitW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['size'],  # argument names to use as an x-axis for the plot\n",
    "        x_vals = [2**i for i in range(5, 13)],\n",
    "        # x_vals=[\n",
    "            # 128 * i for i in range(2, 33)\n",
    "        # ],  # different possible values for `x_name`\n",
    "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
    "        # possible values for `line_arg``\n",
    "        line_vals=['pytorch', 'triton', 'triton-split'],\n",
    "        # label name for the lines\n",
    "        line_names=[\"PyTorch\", \"Triton\", \"Triton (split weights)\"],\n",
    "        # line styles\n",
    "        styles=[('green', '-'), ('blue', '-'), ('red', '-')],\n",
    "        ylabel=\"TFLOPS\",  # label name for the y-axis\n",
    "        plot_name=\"partial-gelu-performance\",  # name for the plot. Used also as a file name for saving the plot.\n",
    "        args={\"mode\": \"forward\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def benchmark(size, provider: str, mode: str):\n",
    "    print(f\"{provider} benchmarking on ({size}, {size})...\")\n",
    "    torch_nn = TorchNN(size)\n",
    "    linear_weights = torch_nn.linear.state_dict()[\"weight\"].T.contiguous()\n",
    "    Wl, Wr = torch.chunk(linear_weights, 2, dim=1)\n",
    "    Wl = Wl.contiguous()\n",
    "    Wr = Wr.contiguous()\n",
    "    x = torch.randn((size, size), device='cuda', dtype=torch.float16)\n",
    "    if provider == 'pytorch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch_nn.forward(x))\n",
    "    if provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: gelu_partial_layer(x, linear_weights))\n",
    "    if provider == 'triton-split':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: gelu_partial_layer_splitW(x, Wl, Wr))\n",
    "    perf = lambda ms: 2 * size * size * size  * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "def run_benchmarks():\n",
    "    print(\"Running benchmark...\")\n",
    "    benchmark.run(print_data=True, save_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark...\n",
      "pytorch benchmarking on (32, 32)...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_benchmarks()\n",
      "Cell \u001b[0;32mIn[14], line 41\u001b[0m, in \u001b[0;36mrun_benchmarks\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_benchmarks\u001b[39m():\n\u001b[1;32m     40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRunning benchmark...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     benchmark\u001b[39m.\u001b[39;49mrun(print_data\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/triton/python/triton/testing.py:320\u001b[0m, in \u001b[0;36mMark.run\u001b[0;34m(self, show_plots, print_data, save_path)\u001b[0m\n\u001b[1;32m    318\u001b[0m     html\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m<html><body>\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    319\u001b[0m \u001b[39mfor\u001b[39;00m bench \u001b[39min\u001b[39;00m benchmarks:\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(bench, save_path, show_plots, print_data)\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m save_path:\n\u001b[1;32m    322\u001b[0m         html\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<image src=\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00mbench\u001b[39m.\u001b[39mplot_name\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m/>\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/triton/python/triton/testing.py:275\u001b[0m, in \u001b[0;36mMark._run\u001b[0;34m(self, bench, save_path, show_plots, print_data)\u001b[0m\n\u001b[1;32m    273\u001b[0m row_mean, row_min, row_max \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m    274\u001b[0m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m bench\u001b[39m.\u001b[39mline_vals:\n\u001b[0;32m--> 275\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mx_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{bench\u001b[39m.\u001b[39;49mline_arg: y}, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbench\u001b[39m.\u001b[39;49margs)\n\u001b[1;32m    276\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m         y_mean, y_min, y_max \u001b[39m=\u001b[39m ret\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(size, provider, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@triton\u001b[39m\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39mperf_report(\n\u001b[1;32m      2\u001b[0m     triton\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39mBenchmark(\n\u001b[1;32m      3\u001b[0m         x_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msize\u001b[39m\u001b[39m'\u001b[39m],  \u001b[39m# argument names to use as an x-axis for the plot\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbenchmark\u001b[39m(size, provider: \u001b[39mstr\u001b[39m, mode: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprovider\u001b[39m}\u001b[39;00m\u001b[39m benchmarking on (\u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m)...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     torch_nn \u001b[39m=\u001b[39m TorchNN(size)\n\u001b[1;32m     25\u001b[0m     linear_weights \u001b[39m=\u001b[39m torch_nn\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mstate_dict()[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m     26\u001b[0m     Wl, Wr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(linear_weights, \u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mTorchNN.__init__\u001b[0;34m(self, d_model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, d_model: \u001b[39mint\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# TODO: Add the bias back once the bias addition is added to the triton kernel\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mLinear(d_model, \u001b[39m8\u001b[39;49m \u001b[39m*\u001b[39;49m d_model, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16, bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgelu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mGELU()\n\u001b[1;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz1: torch\u001b[39m.\u001b[39mTensor \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[39m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     init\u001b[39m.\u001b[39;49mkaiming_uniform_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, a\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49msqrt(\u001b[39m5\u001b[39;49m))\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         fan_in, _ \u001b[39m=\u001b[39m init\u001b[39m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/init.py:412\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m bound \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m) \u001b[39m*\u001b[39m std  \u001b[39m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49muniform_(\u001b[39m-\u001b[39;49mbound, bound)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "run_benchmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "batch_size = 32\n",
    "\n",
    "x = torch.randn((batch_size, d_model), device='cuda', dtype=torch.float16)\n",
    "linear = torch.nn.Linear(d_model, 8 * d_model, device='cuda', dtype=torch.float16, bias=False)\n",
    "linear_weights = linear.state_dict()[\"weight\"].T.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 512]), torch.Size([64, 256]), torch.Size([64, 256]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wl, Wr = torch.chunk(linear_weights, 2, dim=1)\n",
    "Wl = Wl.contiguous()\n",
    "Wr = Wr.contiguous()\n",
    "linear_weights.shape, Wl.shape, Wr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linear(x)\n",
    "z1, z2 = torch.chunk(Z, 2, dim=(Z.ndim - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), torch.Size([32, 256]), torch.Size([32, 256]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape, z1.shape, z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.6680e-01, -3.7378e-01,  1.6577e-01,  ...,  4.0894e-01,\n",
       "          3.7036e-01, -4.9438e-01],\n",
       "        [-3.8428e-01, -7.6074e-01,  7.0312e-01,  ..., -2.4426e-01,\n",
       "         -2.4121e-01,  4.2407e-01],\n",
       "        [-7.4072e-01, -1.7810e-01, -2.4487e-01,  ...,  7.5049e-01,\n",
       "          7.0496e-02,  4.6680e-01],\n",
       "        ...,\n",
       "        [-5.4980e-01, -7.3047e-01,  2.4622e-01,  ...,  6.0742e-01,\n",
       "         -1.1597e-01, -2.4854e-01],\n",
       "        [ 5.9717e-01, -2.8809e-01, -5.0098e-01,  ..., -1.0176e-03,\n",
       "         -2.9810e-01,  1.2067e-01],\n",
       "        [-1.1514e+00, -4.2114e-01,  1.3311e+00,  ..., -5.4199e-01,\n",
       "          1.5076e-01, -3.3569e-01]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ linear_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.6680e-01, -3.7378e-01,  1.6577e-01,  ...,  4.0894e-01,\n",
       "          3.7036e-01, -4.9438e-01],\n",
       "        [-3.8428e-01, -7.6074e-01,  7.0312e-01,  ..., -2.4426e-01,\n",
       "         -2.4121e-01,  4.2407e-01],\n",
       "        [-7.4072e-01, -1.7810e-01, -2.4487e-01,  ...,  7.5049e-01,\n",
       "          7.0496e-02,  4.6680e-01],\n",
       "        ...,\n",
       "        [-5.4980e-01, -7.3047e-01,  2.4622e-01,  ...,  6.0742e-01,\n",
       "         -1.1597e-01, -2.4854e-01],\n",
       "        [ 5.9717e-01, -2.8809e-01, -5.0098e-01,  ..., -1.0176e-03,\n",
       "         -2.9810e-01,  1.2067e-01],\n",
       "        [-1.1514e+00, -4.2114e-01,  1.3311e+00,  ..., -5.4199e-01,\n",
       "          1.5076e-01, -3.3569e-01]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9668, -0.3738,  0.1658,  ..., -0.3020, -0.3372,  0.3347],\n",
       "        [-0.3843, -0.7607,  0.7031,  ..., -0.5679, -0.4856, -0.6963],\n",
       "        [-0.7407, -0.1781, -0.2449,  ..., -0.4575, -0.8945, -0.4456],\n",
       "        ...,\n",
       "        [-0.5498, -0.7305,  0.2462,  ...,  0.5728,  0.1236, -0.5962],\n",
       "        [ 0.5972, -0.2881, -0.5010,  ..., -0.3232,  0.2883,  0.1147],\n",
       "        [-1.1514, -0.4211,  1.3311,  ..., -0.8276, -1.5098, -0.3279]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ Wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7048e-02,  3.9453e-01,  9.5749e-03,  ...,  4.0894e-01,\n",
       "          3.7036e-01, -4.9438e-01],\n",
       "        [ 1.0566e+00, -8.2886e-02, -4.0674e-01,  ..., -2.4426e-01,\n",
       "         -2.4121e-01,  4.2407e-01],\n",
       "        [ 1.2100e+00, -4.3555e-01, -1.7224e-01,  ...,  7.5049e-01,\n",
       "          7.0496e-02,  4.6680e-01],\n",
       "        ...,\n",
       "        [-2.1881e-02,  3.4497e-01,  2.2766e-01,  ...,  6.0742e-01,\n",
       "         -1.1597e-01, -2.4854e-01],\n",
       "        [ 9.3311e-01,  7.9199e-01, -1.2805e-01,  ..., -1.0176e-03,\n",
       "         -2.9810e-01,  1.2067e-01],\n",
       "        [-3.6548e-01,  7.4036e-02, -5.0586e-01,  ..., -5.4199e-01,\n",
       "          1.5076e-01, -3.3569e-01]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ Wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = gelu_partial_layer_splitW(x, Wl, Wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

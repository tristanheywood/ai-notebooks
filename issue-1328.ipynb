{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([2,1,1,1], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39madd(b, c)\n\u001b[1;32m      7\u001b[0m fn_compiled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcompile(forward)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(fn_compiled())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:235\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    236\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:372\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[39mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    371\u001b[0m \u001b[39mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m callback(frame, cache_size, hooks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:404\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m counters[\u001b[39m\"\u001b[39m\u001b[39mframes\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     result \u001b[39m=\u001b[39m inner_convert(frame, cache_size, hooks)\n\u001b[1;32m    405\u001b[0m     counters[\u001b[39m\"\u001b[39m\u001b[39mframes\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:104\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m torch\u001b[39m.\u001b[39mfx\u001b[39m.\u001b[39mgraph_module\u001b[39m.\u001b[39m_forward_from_src \u001b[39m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:262\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    260\u001b[0m initial_grad_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m _compile(\n\u001b[1;32m    263\u001b[0m     frame\u001b[39m.\u001b[39;49mf_code,\n\u001b[1;32m    264\u001b[0m     frame\u001b[39m.\u001b[39;49mf_globals,\n\u001b[1;32m    265\u001b[0m     frame\u001b[39m.\u001b[39;49mf_locals,\n\u001b[1;32m    266\u001b[0m     frame\u001b[39m.\u001b[39;49mf_builtins,\n\u001b[1;32m    267\u001b[0m     compiler_fn,\n\u001b[1;32m    268\u001b[0m     one_graph,\n\u001b[1;32m    269\u001b[0m     export,\n\u001b[1;32m    270\u001b[0m     hooks,\n\u001b[1;32m    271\u001b[0m     frame,\n\u001b[1;32m    272\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:164\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    166\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:324\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39mfor\u001b[39;00m attempt \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcount():\n\u001b[1;32m    323\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m         out_code \u001b[39m=\u001b[39m transform_code_object(code, transform)\n\u001b[1;32m    325\u001b[0m         orig_code_map[out_code] \u001b[39m=\u001b[39m code\n\u001b[1;32m    326\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:530\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    527\u001b[0m instructions \u001b[39m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m    528\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 530\u001b[0m transformations(instructions, code_options)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:311\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mnonlocal\u001b[39;00m output\n\u001b[1;32m    299\u001b[0m tracer \u001b[39m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    300\u001b[0m     instructions,\n\u001b[1;32m    301\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m tracer\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    312\u001b[0m output \u001b[39m=\u001b[39m tracer\u001b[39m.\u001b[39moutput\n\u001b[1;32m    313\u001b[0m \u001b[39massert\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1862\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1861\u001b[0m     _step_logger()(logging\u001b[39m.\u001b[39mINFO, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorchdynamo start tracing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1862\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:619\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mpush_tx(\u001b[39mself\u001b[39m)\n\u001b[1;32m    616\u001b[0m     \u001b[39mwhile\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstruction_pointer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    618\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mshould_exit\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    620\u001b[0m     ):\n\u001b[1;32m    621\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:583\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, inst\u001b[39m.\u001b[39mopname):\n\u001b[1;32m    582\u001b[0m         unimplemented(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmissing: \u001b[39m\u001b[39m{\u001b[39;00minst\u001b[39m.\u001b[39mopname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, inst\u001b[39m.\u001b[39;49mopname)(inst)\n\u001b[1;32m    585\u001b[0m     \u001b[39mreturn\u001b[39;00m inst\u001b[39m.\u001b[39mopname \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRETURN_VALUE\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m \u001b[39mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1941\u001b[0m, in \u001b[0;36mInstructionTranslator.RETURN_VALUE\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1936\u001b[0m _step_logger()(\n\u001b[1;32m   1937\u001b[0m     logging\u001b[39m.\u001b[39mINFO,\n\u001b[1;32m   1938\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorchdynamo done tracing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_name\u001b[39m}\u001b[39;00m\u001b[39m (RETURN_VALUE)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1939\u001b[0m )\n\u001b[1;32m   1940\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRETURN_VALUE triggered compile\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1941\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39;49mcompile_subgraph(\n\u001b[1;32m   1942\u001b[0m     \u001b[39mself\u001b[39;49m, reason\u001b[39m=\u001b[39;49mGraphCompileReason(\u001b[39m\"\u001b[39;49m\u001b[39mreturn_value\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_summary()])\n\u001b[1;32m   1943\u001b[0m )\n\u001b[1;32m   1944\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39madd_output_instructions([create_instruction(\u001b[39m\"\u001b[39m\u001b[39mRETURN_VALUE\u001b[39m\u001b[39m\"\u001b[39m)])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:555\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_output_instructions(random_calls_instructions)\n\u001b[1;32m    544\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    545\u001b[0m     stack_values\n\u001b[1;32m    546\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    552\u001b[0m ):\n\u001b[1;32m    553\u001b[0m     \u001b[39m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_output_instructions(\n\u001b[0;32m--> 555\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_and_call_fx_graph(tx, \u001b[39mlist\u001b[39;49m(\u001b[39mreversed\u001b[39;49m(stack_values)), root)\n\u001b[1;32m    556\u001b[0m         \u001b[39m+\u001b[39m [create_instruction(\u001b[39m\"\u001b[39m\u001b[39mUNPACK_SEQUENCE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(stack_values))]\n\u001b[1;32m    557\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     graph_output_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_var(\u001b[39m\"\u001b[39m\u001b[39mgraph_out\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:626\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    624\u001b[0m assert_no_fake_params_or_buffers(gm)\n\u001b[1;32m    625\u001b[0m \u001b[39mwith\u001b[39;00m tracing(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracing_context):\n\u001b[0;32m--> 626\u001b[0m     compiled_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_user_compiler(gm)\n\u001b[1;32m    627\u001b[0m compiled_fn \u001b[39m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m    629\u001b[0m counters[\u001b[39m\"\u001b[39m\u001b[39mstats\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39munique_graphs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:164\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    166\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:708\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    706\u001b[0m     compiled_fn \u001b[39m=\u001b[39m compiler_fn(gm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexample_inputs())\n\u001b[1;32m    707\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m     compiled_fn \u001b[39m=\u001b[39m compiler_fn(gm, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfake_example_inputs())\n\u001b[1;32m    709\u001b[0m _step_logger()(logging\u001b[39m.\u001b[39mINFO, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdone compiler function \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    710\u001b[0m \u001b[39massert\u001b[39;00m callable(compiled_fn), \u001b[39m\"\u001b[39m\u001b[39mcompiler_fn did not return callable\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:1055\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     compiled_gm \u001b[39m=\u001b[39m compiler_fn(gm, example_inputs)\n\u001b[1;32m   1057\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/__init__.py:1393\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, model_, inputs_):\n\u001b[1;32m   1391\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_inductor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompile_fx\u001b[39;00m \u001b[39mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 1393\u001b[0m     \u001b[39mreturn\u001b[39;00m compile_fx(model_, inputs_, config_patches\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:488\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[0m\n\u001b[1;32m    484\u001b[0m     decompositions \u001b[39m=\u001b[39m select_decomp_table()\n\u001b[1;32m    485\u001b[0m \u001b[39m# TODO: can add logging before/after the call to create_aot_dispatcher_function\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m# in torch._functorch/aot_autograd.py::aot_module_simplified::aot_function_simplified::new_func\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m# once torchdynamo is merged into pytorch\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m \u001b[39mreturn\u001b[39;00m aot_autograd(\n\u001b[1;32m    489\u001b[0m     fw_compiler\u001b[39m=\u001b[39;49mfw_compiler,\n\u001b[1;32m    490\u001b[0m     bw_compiler\u001b[39m=\u001b[39;49mbw_compiler,\n\u001b[1;32m    491\u001b[0m     decompositions\u001b[39m=\u001b[39;49mdecompositions,\n\u001b[1;32m    492\u001b[0m     partition_fn\u001b[39m=\u001b[39;49mfunctools\u001b[39m.\u001b[39;49mpartial(\n\u001b[1;32m    493\u001b[0m         min_cut_rematerialization_partition, compiler\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minductor\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    494\u001b[0m     ),\n\u001b[1;32m    495\u001b[0m     keep_inference_input_mutations\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m )(model_, example_inputs_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/backends/common.py:48\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[39m# NB: NOT cloned!\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39mwith\u001b[39;00m enable_aot_logging():\n\u001b[0;32m---> 48\u001b[0m         cg \u001b[39m=\u001b[39m aot_module_simplified(gm, example_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m         counters[\u001b[39m\"\u001b[39m\u001b[39maot_autograd\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[39mreturn\u001b[39;00m eval_frame\u001b[39m.\u001b[39mdisable(cg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2818\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums, keep_inference_input_mutations)\u001b[0m\n\u001b[1;32m   2815\u001b[0m full_args\u001b[39m.\u001b[39mextend(params_flat)\n\u001b[1;32m   2816\u001b[0m full_args\u001b[39m.\u001b[39mextend(args)\n\u001b[0;32m-> 2818\u001b[0m compiled_fn \u001b[39m=\u001b[39m create_aot_dispatcher_function(\n\u001b[1;32m   2819\u001b[0m     functional_call,\n\u001b[1;32m   2820\u001b[0m     full_args,\n\u001b[1;32m   2821\u001b[0m     aot_config,\n\u001b[1;32m   2822\u001b[0m )\n\u001b[1;32m   2824\u001b[0m \u001b[39m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[39m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m   2826\u001b[0m \u001b[39m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m   2827\u001b[0m \u001b[39m# convention.  This should get fixed...\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39mruntime_args):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:164\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    166\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2511\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2508\u001b[0m compiler_fn \u001b[39m=\u001b[39m partial(aot_wrapper_dedupe, compiler_fn\u001b[39m=\u001b[39mcompiler_fn)\n\u001b[1;32m   2509\u001b[0m \u001b[39m# You can put more passes here\u001b[39;00m\n\u001b[0;32m-> 2511\u001b[0m compiled_fn \u001b[39m=\u001b[39m compiler_fn(flat_fn, fake_flat_args, aot_config)\n\u001b[1;32m   2513\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(compiled_fn, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2514\u001b[0m     compiled_fn \u001b[39m=\u001b[39m make_boxed_func(compiled_fn)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1715\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn)\u001b[0m\n\u001b[1;32m   1712\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m     \u001b[39mif\u001b[39;00m ok:\n\u001b[0;32m-> 1715\u001b[0m         \u001b[39mreturn\u001b[39;00m compiler_fn(flat_fn, leaf_flat_args, aot_config)\n\u001b[1;32m   1717\u001b[0m \u001b[39m# Strategy 2: Duplicate specialize.\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[39m# In Haskell types, suppose you have:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[39m#   }\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[39m#   keep_arg_mask = [True, True, False, True]\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m seen_args \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1326\u001b[0m, in \u001b[0;36maot_dispatch_base\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   1323\u001b[0m context \u001b[39m=\u001b[39m disable_autocast_manager \u001b[39mif\u001b[39;00m disable_amp \u001b[39melse\u001b[39;00m nullcontext\n\u001b[1;32m   1325\u001b[0m \u001b[39mwith\u001b[39;00m context(), track_graph_compiling(aot_config, \u001b[39m\"\u001b[39m\u001b[39minference\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1326\u001b[0m     compiled_fw \u001b[39m=\u001b[39m aot_config\u001b[39m.\u001b[39;49mfw_compiler(fw_module, flat_args_with_views_handled)\n\u001b[1;32m   1328\u001b[0m compiled_fn \u001b[39m=\u001b[39m create_runtime_wrapper(\n\u001b[1;32m   1329\u001b[0m     compiled_fw,\n\u001b[1;32m   1330\u001b[0m     runtime_metadata\u001b[39m=\u001b[39mmetadata_,\n\u001b[1;32m   1331\u001b[0m     trace_joint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1332\u001b[0m     keep_input_mutations\u001b[39m=\u001b[39maot_config\u001b[39m.\u001b[39mkeep_inference_input_mutations\n\u001b[1;32m   1333\u001b[0m )\n\u001b[1;32m   1335\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:164\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    166\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:462\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler\u001b[0;34m(model, example_inputs)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39m# Why convert outplace op to inplace? Inductor can support inplace operations well and for custom\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m# inplace ops which are lowered as ExternKernel, it is beneficial to performance when the inplace\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m# implementation is used if available.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m model \u001b[39m=\u001b[39m convert_outplace_to_inplace(model)\n\u001b[0;32m--> 462\u001b[0m \u001b[39mreturn\u001b[39;00m inner_compile(\n\u001b[1;32m    463\u001b[0m     model,\n\u001b[1;32m    464\u001b[0m     example_inputs,\n\u001b[1;32m    465\u001b[0m     num_fixed\u001b[39m=\u001b[39;49mfixed,\n\u001b[1;32m    466\u001b[0m     cudagraphs\u001b[39m=\u001b[39;49mcudagraphs,\n\u001b[1;32m    467\u001b[0m     graph_id\u001b[39m=\u001b[39;49mgraph_id,\n\u001b[1;32m    468\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:595\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m     compiled_fn\u001b[39m.\u001b[39m_boxed_call \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     compiled_fn \u001b[39m=\u001b[39m compiler_fn(gm, example_inputs)\n\u001b[1;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/debug.py:239\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    238\u001b[0m     \u001b[39mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:180\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[39mwith\u001b[39;00m V\u001b[39m.\u001b[39mset_graph_handler(graph):\n\u001b[1;32m    179\u001b[0m         graph\u001b[39m.\u001b[39mrun(\u001b[39m*\u001b[39mexample_inputs)\n\u001b[0;32m--> 180\u001b[0m         compiled_fn \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mcompile_to_fn()\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cudagraphs:\n\u001b[1;32m    183\u001b[0m     complex_memory_overlap_inputs \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[1;32m    184\u001b[0m         complex_memory_overlap(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m example_inputs\n\u001b[1;32m    185\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:618\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile_to_fn\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_to_module()\u001b[39m.\u001b[39mcall\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:164\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 164\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    166\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:607\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m    605\u001b[0m     \u001b[39mprint\u001b[39m(code)\n\u001b[0;32m--> 607\u001b[0m mod \u001b[39m=\u001b[39m PyCodeCache\u001b[39m.\u001b[39;49mload(code)\n\u001b[1;32m    608\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    609\u001b[0m     \u001b[39msetattr\u001b[39m(mod, name, value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/codecache.py:608\u001b[0m, in \u001b[0;36mPyCodeCache.load\u001b[0;34m(cls, source_code, extra)\u001b[0m\n\u001b[1;32m    606\u001b[0m mod\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m \u001b[39m=\u001b[39m path\n\u001b[1;32m    607\u001b[0m mod\u001b[39m.\u001b[39mkey \u001b[39m=\u001b[39m key\n\u001b[0;32m--> 608\u001b[0m exec(code, mod\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m, mod\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m)\n\u001b[1;32m    609\u001b[0m \u001b[39m# another thread might set this first\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache\u001b[39m.\u001b[39msetdefault(key, mod)\n",
      "File \u001b[0;32m/tmp/torchinductor_trist/6y/c6yhysc2oh2bugnw6io7wafzkt6cjyzu4ppbd4c52ecp5vkevx4m.py:53\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# kernel path: /tmp/torchinductor_trist/mu/cmundq7g3v5hcjbrpnmk56so2mveov3pxl2qoqmakemv6fikyshb.py\u001b[39;00m\n\u001b[1;32m     21\u001b[0m triton__0 \u001b[39m=\u001b[39m async_compile\u001b[39m.\u001b[39mtriton(\u001b[39m'''\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport triton\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport triton.language as tl\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    tl.store(out_ptr1 + (r0 + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp4, rmask)\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[39m'''\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m async_compile\u001b[39m.\u001b[39;49mwait(\u001b[39mglobals\u001b[39;49m())\n\u001b[1;32m     54\u001b[0m \u001b[39mdel\u001b[39;00m async_compile\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(args):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/codecache.py:795\u001b[0m, in \u001b[0;36mAsyncCompile.wait\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m    793\u001b[0m             pbar\u001b[39m.\u001b[39mset_postfix_str(key)\n\u001b[1;32m    794\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, (Future, TritonFuture)):\n\u001b[0;32m--> 795\u001b[0m             scope[key] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    796\u001b[0m             pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m    798\u001b[0m _compile_end()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/codecache.py:653\u001b[0m, in \u001b[0;36mTritonFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\n\u001b[1;32m    652\u001b[0m \u001b[39m# If the worker failed this will throw an exception.\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfuture\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    654\u001b[0m kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m _load_kernel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_code)\n\u001b[1;32m    655\u001b[0m latency \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m t0\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "x = torch.rand([2,1,1,1], device='cuda')\n",
    "def forward():\n",
    "    a = x.argmax(3) # [2,1,1]\n",
    "    b = a.max(2).values #[2,1]\n",
    "    c = b.sum(0) # [1]\n",
    "    return torch.add(b, c)\n",
    "fn_compiled = torch.compile(forward)\n",
    "print(fn_compiled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid, start_graph, end_graph\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "# kernel path: /tmp/torchinductor_trist/mu/cmundq7g3v5hcjbrpnmk56so2mveov3pxl2qoqmakemv6fikyshb.py\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import persistent_reduction\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@persistent_reduction(\n",
      "    size_hints=[1, 2],\n",
      "    reduction_hint=ReductionHint.INNER,\n",
      "    filename=__file__,\n",
      "    meta={'signature': {0: '*i64', 1: 'i32', 2: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=())]}\n",
      ")\n",
      "@triton.jit\n",
      "def triton_(out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n",
      "    xnumel = 1\n",
      "    rnumel = 2\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "    xmask = xindex < xnumel\n",
      "    rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "    rmask = rindex < rnumel\n",
      "    r0 = rindex\n",
      "    tmp0 = 0\n",
      "    tmp2 = tl.where(rmask, tmp0, 0)\n",
      "    tmp3 = tl.sum(tmp2, 1)[:, None]\n",
      "    tmp4 = tmp0 + tmp3\n",
      "    tl.store(out_ptr1 + (r0 + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp4, rmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    arg0_1, = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf1 = empty_strided((2, 1), (1, 1), device='cuda', dtype=torch.int64)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf1, 1, 2, grid=grid(1), stream=stream0)\n",
      "        return (buf1, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    arg0_1 = rand_strided((2, 1, 1, 1), (1, 1, 1, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([arg0_1]))\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "!cat /tmp/torchinductor_trist/6y/c6yhysc2oh2bugnw6io7wafzkt6cjyzu4ppbd4c52ecp5vkevx4m.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def kernel(out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n",
    "    xnumel = 1\n",
    "    rnumel = 2\n",
    "    xoffset = tl.program_id(0) * XBLOCK\n",
    "    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
    "    xmask = xindex < xnumel\n",
    "    rindex = tl.arange(0, RBLOCK)[None, :]\n",
    "    rmask = rindex < rnumel\n",
    "    r0 = rindex\n",
    "    tmp0 = 0\n",
    "    tmp2 = tl.where(rmask, tmp0, 0)\n",
    "    tmp3 = tl.sum(tmp2, 1)[:, None]\n",
    "    tmp4 = tmp0 + tmp3\n",
    "    tl.store(out_ptr1 + (r0 + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp4, rmask)\n",
    "    tl.store(out_ptr1 + )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import empty_strided\n",
    "from torch._inductor.triton_ops.autotune import persistent_reduction\n",
    "\n",
    "\n",
    "def dispatch():\n",
    "    buf1 = empty_strided((2, 1), (1, 1), device='cuda', dtype=torch.int64)\n",
    "    kernel[(1,)](buf1, 1, 2, XBLOCK=1, RBLOCK=2)\n",
    "    return (buf1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = empty_strided((2, 1), (1, 1), device='cuda', dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
